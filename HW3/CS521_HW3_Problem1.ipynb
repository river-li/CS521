{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/river-li/CS521/blob/main/CS521_HW3_Problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAJcPRUdhFWi"
      },
      "source": [
        "## Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVRMQrk0hIKc",
        "outputId": "a43b4912-4b24-43bd-d890-7ed7a625b289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no input normalization\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreActResNet(\n",
              "  (normalize): Normalize()\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): PreActBlock(\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): PreActBlock(\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "# from tensorboardX import SummaryWriter\n",
        "\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.CIFAR10('cifar10_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.CIFAR10('cifar10_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "def tp_relu(x, delta=1.):\n",
        "    ind1 = (x < -1. * delta).float()\n",
        "    ind2 = (x > delta).float()\n",
        "    return .5 * (x + delta) * (1 - ind1) * (1 - ind2) + x * ind2\n",
        "\n",
        "def tp_smoothed_relu(x, delta=1.):\n",
        "    ind1 = (x < -1. * delta).float()\n",
        "    ind2 = (x > delta).float()\n",
        "    return (x + delta) ** 2 / (4 * delta) * (1 - ind1) * (1 - ind2) + x * ind2\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def __init__(self, mu, std):\n",
        "        super(Normalize, self).__init__()\n",
        "        self.mu, self.std = mu, std\n",
        "\n",
        "    def forward(self, x):\n",
        "        return (x - self.mu) / self.std\n",
        "\n",
        "class IdentityLayer(nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "class PreActBlock(nn.Module):\n",
        "    '''Pre-activation version of the BasicBlock.'''\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, bn, learnable_bn, stride=1, activation='relu'):\n",
        "        super(PreActBlock, self).__init__()\n",
        "        self.collect_preact = True\n",
        "        self.activation = activation\n",
        "        self.avg_preacts = []\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes, affine=learnable_bn) if bn else IdentityLayer()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=not learnable_bn)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine=learnable_bn) if bn else IdentityLayer()\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=not learnable_bn)\n",
        "\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=not learnable_bn)\n",
        "            )\n",
        "\n",
        "    def act_function(self, preact):\n",
        "        if self.activation == 'relu':\n",
        "            act = F.relu(preact)\n",
        "        elif self.activation[:6] == '3prelu':\n",
        "            act = tp_relu(preact, delta=float(self.activation.split('relu')[1]))\n",
        "        elif self.activation[:8] == '3psmooth':\n",
        "            act = tp_smoothed_relu(preact, delta=float(self.activation.split('smooth')[1]))\n",
        "        else:\n",
        "            assert self.activation[:8] == 'softplus'\n",
        "            beta = int(self.activation.split('softplus')[1])\n",
        "            act = F.softplus(preact, beta=beta)\n",
        "        return act\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.act_function(self.bn1(x))\n",
        "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x  # Important: using out instead of x\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(self.act_function(self.bn2(out)))\n",
        "        out += shortcut\n",
        "        return out\n",
        "\n",
        "class PreActResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, n_cls, cuda=True, half_prec=False,\n",
        "        activation='relu', fts_before_bn=False, normal='none'):\n",
        "        super(PreActResNet, self).__init__()\n",
        "        self.bn = True\n",
        "        self.learnable_bn = True  # doesn't matter if self.bn=False\n",
        "        self.in_planes = 64\n",
        "        self.avg_preact = None\n",
        "        self.activation = activation\n",
        "        self.fts_before_bn = fts_before_bn\n",
        "        if normal == 'cifar10':\n",
        "            self.mu = torch.tensor((0.4914, 0.4822, 0.4465)).view(1, 3, 1, 1)\n",
        "            self.std = torch.tensor((0.2471, 0.2435, 0.2616)).view(1, 3, 1, 1)\n",
        "        else:\n",
        "            self.mu = torch.tensor((0.0, 0.0, 0.0)).view(1, 3, 1, 1)\n",
        "            self.std = torch.tensor((1.0, 1.0, 1.0)).view(1, 3, 1, 1)\n",
        "            print('no input normalization')\n",
        "        if cuda:\n",
        "            self.mu = self.mu.cuda()\n",
        "            self.std = self.std.cuda()\n",
        "        if half_prec:\n",
        "            self.mu = self.mu.half()\n",
        "            self.std = self.std.half()\n",
        "\n",
        "        self.normalize = Normalize(self.mu, self.std)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=not self.learnable_bn)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.bn = nn.BatchNorm2d(512 * block.expansion)\n",
        "        self.linear = nn.Linear(512*block.expansion, n_cls)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, self.bn, self.learnable_bn, stride, self.activation))\n",
        "            # layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        for layer in [*self.layer1, *self.layer2, *self.layer3, *self.layer4]:\n",
        "            layer.avg_preacts = []\n",
        "\n",
        "        out = self.normalize(x)\n",
        "        out = self.conv1(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        if return_features and self.fts_before_bn:\n",
        "            return out.view(out.size(0), -1)\n",
        "        out = F.relu(self.bn(out))\n",
        "        if return_features:\n",
        "            return out.view(out.size(0), -1)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def PreActResNet18(n_cls, cuda=True, half_prec=False, activation='relu', fts_before_bn=False,\n",
        "    normal='none'):\n",
        "    #print('initializing PA RN-18 with act {}, normal {}'.format())\n",
        "    return PreActResNet(PreActBlock, [2, 2, 2, 2], n_cls=n_cls, cuda=cuda, half_prec=half_prec,\n",
        "        activation=activation, fts_before_bn=fts_before_bn, normal=normal)\n",
        "\n",
        "\n",
        "# intialize the model\n",
        "model = PreActResNet18(10, cuda=True, activation='softplus1').to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90-CRvUNhrAp"
      },
      "source": [
        "### Implement the Attacks\n",
        "\n",
        "\n",
        "Functions are given a simple useful signature that you can start with. Feel free to extend the signature as you see fit.\n",
        "\n",
        "You may find it useful to create a 'batched' version of PGD that you can use to create the adversarial attack.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "scC-5nOKhpEe"
      },
      "outputs": [],
      "source": [
        "def pgd_linf_untargeted(model, x, labels, k, eps, eps_step):\n",
        "    model.eval()\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "    adv_x = x.clone().detach()\n",
        "    adv_x.requires_grad_(True)\n",
        "    for _ in range(k):\n",
        "        adv_x.requires_grad_(True)\n",
        "        model.zero_grad()\n",
        "        output = model(adv_x)\n",
        "        # TODO: Calculate the loss\n",
        "        loss = ce_loss(output, labels)\n",
        "        loss.backward()\n",
        "        # TODO: compute the adv_x\n",
        "        # find delta, clamp with eps\n",
        "        grad_sign = adv_x.grad.data.sign()\n",
        "        adv_x = adv_x.detach() + eps_step * grad_sign\n",
        "        delta = torch.clamp(adv_x - x, min=-eps, max=eps)\n",
        "        adv_x = torch.clamp(x + delta, min=0, max=1).detach()\n",
        "    return adv_x\n",
        "\n",
        "def pgd_l2_untargeted(model, x, labels, k, eps, eps_step):\n",
        "    model.eval()\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "    adv_x = x.clone().detach()\n",
        "    adv_x.requires_grad_(True)\n",
        "    for _ in range(k):\n",
        "        adv_x.requires_grad_(True)\n",
        "        model.zero_grad()\n",
        "        output = model(adv_x)\n",
        "        batch_size = x.size()[0]\n",
        "        # TODO: Calculate the loss\n",
        "        loss = ce_loss(output, labels)\n",
        "        loss.backward()\n",
        "        grad = adv_x.grad.data\n",
        "        # TODO: compute the adv_x\n",
        "        # find delta, clamp with eps, project delta to the l2 ball\n",
        "        # HINT: https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/torchattacks/attacks/pgdl2.py\n",
        "        grad_norms = torch.norm(grad.view(batch_size, -1), p=2, dim=1) + 1e-10\n",
        "        grad = grad / grad_norms.view(batch_size, 1, 1, 1)\n",
        "        adv_x = adv_x.detach() + eps_step * grad\n",
        "        delta = adv_x - x\n",
        "        delta_norms = torch.norm(delta.view(batch_size, -1), p=2, dim=1)\n",
        "        factor = eps / delta_norms\n",
        "        factor = torch.min(factor, torch.ones_like(delta_norms))\n",
        "        delta = delta * factor.view(-1, 1, 1, 1)\n",
        "\n",
        "        adv_x = torch.clamp(x + delta, min=0, max=1).detach()\n",
        "\n",
        "    return adv_x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VPQsmULhwGd"
      },
      "source": [
        "Evaluate Single and Multi-Norm Robust Accuracy\n",
        "In this section, we evaluate the model on the Linf and L2 attacks as well as union accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_linf_untargeted(model, x, labels, eps):\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    model.eval()\n",
        "    x_adv = x.clone().detach().requires_grad_(True)\n",
        "    logits = model(x_adv)\n",
        "    loss = F.cross_entropy(logits, labels)\n",
        "    grad = torch.autograd.grad(loss, x_adv)[0]\n",
        "\n",
        "    # One FGSM step\n",
        "    x_adv = x_adv + eps * torch.sign(grad)\n",
        "\n",
        "    # Project to valid pixel range\n",
        "    x_adv = torch.clamp(x_adv, 0.0, 1.0).detach()\n",
        "    return x_adv"
      ],
      "metadata": {
        "id": "3N6fWdlX0nSm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ezOlliOLhuHL"
      },
      "outputs": [],
      "source": [
        "def test_model_on_single_attack(model, attack='pgd_linf', eps=0.1):\n",
        "    model.eval()\n",
        "    tot_test, tot_acc, tot_acc_adv = 0.0, 0.0, 0.0\n",
        "    for batch_idx, (x_batch, y_batch) in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Evaluating\"):\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        if attack == 'pgd_linf':\n",
        "            # TODO: get x_adv untargeted pgd linf with eps, and eps_step=eps/4\n",
        "            x_adv = pgd_linf_untargeted(model, x_batch, y_batch, 4, eps, eps/4)\n",
        "        elif attack == 'fgsm':\n",
        "            x_adv = fgsm_linf_untargeted(model, x_batch, y_batch, eps)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "        # get the testing accuracy and update tot_test and tot_acc\n",
        "        out_std = model(x_batch)\n",
        "        pred_std = torch.max(out_std, dim=1)[1]\n",
        "\n",
        "        out_adv = model(x_adv)\n",
        "        pred_adv = torch.max(out_adv, dim=1)[1]\n",
        "        tot_acc_adv += (pred_adv == y_batch).sum().item()\n",
        "        tot_acc += (pred_std == y_batch).sum().item()\n",
        "\n",
        "        tot_test += x_batch.size(0)\n",
        "\n",
        "    print('Standard accuracy %.5lf' % (tot_acc/tot_test))\n",
        "    print('Robust accuracy %.5lf' % (tot_acc_adv/tot_test), f'on {attack} attack with eps = {eps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarial Training"
      ],
      "metadata": {
        "id": "0ljm4YNDtYf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcNESYWqzq62"
      },
      "outputs": [],
      "source": [
        "# Device\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "model = PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "\n",
        "def train_standard(model, train_loader, epochs=2, lr=0.1, weight_decay=5e-4):\n",
        "    import torch.optim as optim\n",
        "    model.train()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs//2, int(0.8*epochs)], gamma=0.1)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total, correct, total_loss = 0, 0, 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Standard Train Epoch {ep}/{epochs}\")\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += x.size(0)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "        scheduler.step()\n",
        "\n",
        "def train_adversarial(model, train_loader, epochs=2, lr=0.1, weight_decay=5e-4, pgd_steps=10, eps=8/255.0, eps_step=2/255.0):\n",
        "    import torch.optim as optim\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs//2, int(0.8*epochs)], gamma=0.1)\n",
        "    for ep in range(1, epochs+1):\n",
        "        total, correct, total_loss = 0, 0, 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Adv Train Epoch {ep}/{epochs} (eps={eps:.4f})\")\n",
        "        for x, y in pbar:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            x_adv = pgd_linf_untargeted(model, x, y, k=pgd_steps, eps=eps, eps_step=eps_step)\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x_adv)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total += x.size(0)\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            pbar.set_postfix(loss=total_loss/total, acc=correct/total)\n",
        "        scheduler.step()\n",
        "\n",
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def new_model():\n",
        "    return PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "\n",
        "\n",
        "# Standard training model\n",
        "model_nat = new_model()\n",
        "train_standard(model_nat, train_loader, epochs=10)\n",
        "save_model(model_nat, f\"standard_model.pth\")\n",
        "\n",
        "# Experiments for (a) and (b)\n",
        "eps_values = [4/255.0, 8/255.0, 16/255.0]\n",
        "for eps in eps_values:\n",
        "    # Adversarial training model at this eps\n",
        "    model_adv = new_model()\n",
        "    train_adversarial(model_adv, train_loader, epochs=10, pgd_steps=10, eps=eps, eps_step=eps/4)\n",
        "    save_model(model_adv, f\"adv_pgd_eps_{int(eps*255)}_255_model.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(path):\n",
        "    model = PreActResNet18(10, cuda=use_cuda, activation='softplus1', normal='cifar10').to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n",
        "\n",
        "# Evaluation: standard accuracy\n",
        "@torch.no_grad()\n",
        "def evaluate_standard(model, loader):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Evaluation: robust accuracy under PGD\n",
        "def evaluate_robust_pgd(model, loader, pgd_steps=10, eps=8/255.0, eps_step=2/255.0):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = pgd_linf_untargeted(model, x, y, k=pgd_steps, eps=eps, eps_step=eps_step)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_adv)\n",
        "            pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Evaluation: robust accuracy under FGSM\n",
        "def evaluate_robust_fgsm(model, loader, eps=8/255.0):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = fgsm_linf_untargeted(model, x, y, eps=eps)\n",
        "        with torch.no_grad():\n",
        "            logits = model(x_adv)\n",
        "            pred = logits.argmax(1)\n",
        "        total += x.size(0)\n",
        "        correct += (pred == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "eps_values = [0.0, 8/255.0]\n",
        "\n",
        "model_paths = [\n",
        "    \"standard_model.pth\",\n",
        "    \"adv_pgd_eps_4_255_model.pth\",\n",
        "    \"adv_pgd_eps_8_255_model.pth\",\n",
        "    \"adv_pgd_eps_16_255_model.pth\",\n",
        "]\n",
        "\n",
        "def report_model(path, eps_list, pgd_steps=20):\n",
        "    model = load_model(path)\n",
        "    print(f\"model path: {path}\")\n",
        "\n",
        "    for eps in eps_list:\n",
        "        # PGD robustness\n",
        "        acc = evaluate_robust_pgd(model, test_loader, pgd_steps=pgd_steps, eps=eps, eps_step=(eps/4 if eps>0 else 0.0))\n",
        "\n",
        "        if eps == 0.0:\n",
        "            print(f\"[eps=0, pgd_steps={pgd_steps:d}] Clean acc:  {acc:.4f}\")\n",
        "        else:\n",
        "            print(f\"[eps={eps:.5f}, pgd_steps={pgd_steps:d}] Robust acc: {acc:.4f}\")\n",
        "\n",
        "\n",
        "# Run reports\n",
        "for path in model_paths:\n",
        "    report_model(path, eps_values, 20)\n",
        "    report_model(path, eps_values, 10)\n",
        "    report_model(path, eps_values, 4)"
      ],
      "metadata": {
        "id": "gxpVxvh0t-0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fgsm with eps = 4/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on fgsm attack with model 1 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 2 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 3 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 4 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'fgsm', 4/255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Qp2SxWWug6Z",
        "outputId": "26218245-025e-4551-86b8-977be986fdae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:12<00:00, 12.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.35650\n",
            "Robust accuracy 0.04190 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:10<00:00, 14.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.18070\n",
            "Robust accuracy 0.16330 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:10<00:00, 14.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.12240\n",
            "Robust accuracy 0.11210 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:11<00:00, 14.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on fgsm attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fgsm with eps = 8/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on fgsm attack with model 1 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 2 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 3 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on fgsm attack with model 4 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'fgsm', 8/255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOWq9eQ2Gcyz",
        "outputId": "d9bb8ee0-593a-4210-885d-b941671b5693"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:11<00:00, 14.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.35650\n",
            "Robust accuracy 0.04410 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:10<00:00, 14.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.18070\n",
            "Robust accuracy 0.14410 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:10<00:00, 14.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.12240\n",
            "Robust accuracy 0.10310 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:10<00:00, 14.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on fgsm attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PGD linf with eps = 4/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on Linf attack with model 1 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 2 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 3 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 4 with eps = 4/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 4/255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7yyUsAeGfwm",
        "outputId": "36c3d6cb-0705-4549-b114-7e126327d781"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.35650\n",
            "Robust accuracy 0.01550 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.18070\n",
            "Robust accuracy 0.16340 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.12240\n",
            "Robust accuracy 0.11210 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on pgd_linf attack with eps = 0.01568627450980392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PGD linf with eps = 8/255\n",
        "\n",
        "model.load_state_dict(torch.load('standard_model.pth', map_location=device))\n",
        "# Evaluate on Linf attack with model 1 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_4_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 2 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_8_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 3 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)\n",
        "\n",
        "model.load_state_dict(torch.load('adv_pgd_eps_16_255_model.pth', map_location=device))\n",
        "# # Evaluate on Linf attack with model 4 with eps = 8/255\n",
        "test_model_on_single_attack(model, 'pgd_linf', 8/255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBjRT4YxGiry",
        "outputId": "9a7cd453-62c7-4a28-ecc1-0fd30aeb6c5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.35650\n",
            "Robust accuracy 0.00020 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.18070\n",
            "Robust accuracy 0.14390 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.12240\n",
            "Robust accuracy 0.10310 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 157/157 [00:35<00:00,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard accuracy 0.10000\n",
            "Robust accuracy 0.10000 on pgd_linf attack with eps = 0.03137254901960784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZiwqWFHI4u0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}